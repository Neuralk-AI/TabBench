{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dbed1b6",
   "metadata": {},
   "source": [
    "**What is TabBench?**\n",
    "*TabBench* is a benchmark suite for tabular data focused on real-world business use cases like product categorization, deduplication, and pricing. Unlike academic benchmarks, it evaluates models on industrial datasets from sectors such as retail, banking, and insurance. Built on top of [Neuralk Foundry-CE](https://github.com/Neuralk-AI/NeuralkFoundry-CE), TabBench structures each task as a modular workflow, making it easy to test and compare different approaches. Itâ€™s designed to help identify the best models for practical, industry-driven challenges.\n",
    "\n",
    "# Adding a Dataset to the benchmark\n",
    "\n",
    "Datasets are a core components of TabBench. Big registries exist online such as OpenML or UCI but are reserved to academic datasets. Industrial datasets usually comes with tighter use conditions and licenses that make them unfit for those platforms and require explicit consent of the user before downloading. Unfortunately this restricts the automation capabilities of our benchmark.\n",
    "\n",
    "Neuralk Foundry supports three modes of dataset registration:\n",
    "\n",
    "* **Local datasets**: Files already available on disk can be directly registered and used.\n",
    "* **Remote datasets**: Files hosted online can be downloaded and cached locally. This is useful for sharing datasets across teams or environments.\n",
    "* **OpenML datasets**: Public datasets can be fetched from OpenML, leveraging its large and well-maintained repository.\n",
    "\n",
    "In this tutorial, we show how to add a dataset for each of those sources.\n",
    "\n",
    "## Adding a Locally Generated Dataset\n",
    "\n",
    "Foundry includes utilities to generate synthetic datasets for tasks such as deduplication.\n",
    "In this example, we create a custom deduplication dataset where **70% of the records have at least one duplicate**, with an average of **4 duplicates per duplicated item**. Once the dataset is generated, it is saved locally. To make it available within TabBench, we define a corresponding `DataConfig`, which is automatically registered in the system.\n",
    "\n",
    "For local datasets, the configuration must include the field `file_path`, which specifies the path to the dataset file on disk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec2d21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralk_foundry_ce.utils.data import make_deduplication\n",
    "\n",
    "\n",
    "df, target_col = make_deduplication(num_samples=300, embed_dim=16, dup_frac=0.7, avg_dups=4.0, decay=.4)\n",
    "df.to_parquet('./my_dataset.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6ceaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fake_deduplication'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuralk_foundry_ce.datasets import get_data_config, LocalDataConfig\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataConfig(LocalDataConfig):\n",
    "    name: str='fake_deduplication'\n",
    "    task: str = \"linkage\"\n",
    "    target: str = target_col\n",
    "    file_path: str = \"./my_dataset.parquet\"\n",
    "\n",
    "# Check that the dataset is well imported\n",
    "get_data_config('fake_deduplication').name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e0802a",
   "metadata": {},
   "source": [
    "## Adding an OpenML Dataset\n",
    "\n",
    "Registering a dataset from OpenML is the most straightforward approach.\n",
    "To do so, simply create a configuration class and include the **`openml_id`** field. The dataset ID can be found on the corresponding dataset page at [openml.org](https://www.openml.org).\n",
    "\n",
    "Once specified, the dataset will be automatically downloaded, cached locally, and made available within TabBench.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d57a8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'credit-g'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from neuralk_foundry_ce.datasets import OpenMLDataConfig\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class OpenMLDataConfig(OpenMLDataConfig):\n",
    "    name: str='credit-g'\n",
    "    task: str = \"classification\"\n",
    "    target: str = 'class'\n",
    "    openml_id: int = 31\n",
    "\n",
    "get_data_config('credit-g').name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24aa7ba-a22f-4324-8ceb-4433eb553741",
   "metadata": {},
   "source": [
    "## Adding a Downloadable Dataset\n",
    "\n",
    "To define a downloadable dataset, extend the `DataConfig` class with the following elements:\n",
    "\n",
    "* A `filename` field specifying the name under which the dataset will be stored locally.\n",
    "* A `download_data` method responsible for fetching the dataset and saving it to the designated location within the dataset cache managed by the package.\n",
    "\n",
    "For example, the Best Buy product catalog can be registered this way. In this case, we download the data, retain only the relevant columns, and store the processed file for use in downstream tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8eb1d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import pandas as pd\n",
    "\n",
    "from neuralk_foundry_ce.datasets.base import DownloadDataConfig\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class DataConfig(DownloadDataConfig):\n",
    "    name: str  = \"best_buy_simple_categ_again\"\n",
    "    task: str  = \"classification\"\n",
    "    target: str = \"type\"\n",
    "    file_name: str = 'data.parquet'\n",
    "\n",
    "    def download_data(self, dataset_dir):\n",
    "        ds_url = 'https://raw.githubusercontent.com/BestBuyAPIs/open-data-set/refs/heads/master/products.json'\n",
    "        df = pd.read_json(ds_url)[['name', 'type', 'price', 'manufacturer']]\n",
    "        df = df[df.type.isin(['HardGood', 'Game', 'Software'])]\n",
    "        df = df.reset_index(drop=True)\n",
    "        df.to_parquet(dataset_dir / self.file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef7ca15-de73-4e1d-943d-cce2e0dd77ce",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Neuralk Foundry currently supports three types of dataset sources: **local files**, **downloadable resources**, and **OpenML datasets**. These options cover most common use cases in both research and industry.\n",
    "\n",
    "If you wish to support an additional data source or contribute new tasks, contributions are welcome, feel free to open a pull request!\n",
    "\n",
    "Check the other tutorials:\n",
    "\n",
    "* [1 - Getting Started with TabBench.ipynb](./1%20-%20Getting%20Started%20with%20TabBench.ipynb)\n",
    "\n",
    "* [3 - Use a custom model.ipynb](./3%20-%20Use%20a%20custom%20model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8fe158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the parquet dataset\n",
    "import os\n",
    "file_path = './my_dataset.parquet'\n",
    "if os.path.exists(file_path):\n",
    "    os.remove(\"./my_dataset.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bench_3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
